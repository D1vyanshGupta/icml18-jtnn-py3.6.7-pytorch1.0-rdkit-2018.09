{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import deque\n",
    "\n",
    "from MolJuncTree import MolJuncTree  \n",
    "from ClusterVocab import ClusterVocab \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([x for x in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [x for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.stack(y, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.sum(y, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 10, 15, 20])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_PATH = os.path.join(os.getcwd(), 'data', 'vocab_50.txt')\n",
    "vocab = [x.strip(\"\\r\\n \") for x in open(VOCAB_PATH)]\n",
    "vocab = ClusterVocab(vocab)\n",
    "\n",
    "hidden_size = 3\n",
    "\n",
    "embedding = nn.Embedding(vocab.size(), hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bottom_up_traversal_order(root):\n",
    "    # FIFO queue for BFS traversal\n",
    "    fifo_queue = deque([root])\n",
    "\n",
    "    # set to keep track of visited nodes\n",
    "    visited = set([root.idx])\n",
    "    \n",
    "    # root node is at zeroth depth\n",
    "    root.depth = 0\n",
    "\n",
    "    # list to store appropriate traversal order\n",
    "    bottom_up = []\n",
    "\n",
    "    while len(fifo_queue) > 0:\n",
    "        # pop node from front of the queue\n",
    "        x = fifo_queue.popleft()\n",
    "\n",
    "        # traverse the neighbors\n",
    "        for y in x.neighbors:\n",
    "            if y.idx not in visited:\n",
    "                fifo_queue.append(y)\n",
    "\n",
    "                visited.add(y.idx)\n",
    "\n",
    "                y.depth = x.depth + 1\n",
    "\n",
    "                if y.depth > len(bottom_up):\n",
    "                    # have a separate sublist for every depth\n",
    "                    bottom_up.append([])\n",
    "                \n",
    "                bottom_up[y.depth - 1].append((y, x))\n",
    "\n",
    "    # first we implement bottom-up traversal and then top-down traversal\n",
    "    traversal_order = bottom_up[::-1]\n",
    "\n",
    "    return traversal_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "traversal_order = get_bottom_up_traversal_order(root_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_val = [torch.zeros(hidden_size)] * len(junc_tree_batch[0].nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_val = torch.stack(next_val, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(hidden_size, hidden_size)\n",
    "B = torch.randn(hidden_size, hidden_size)\n",
    "V = torch.randn(hidden_size, hidden_size)\n",
    "U = torch.randn(hidden_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 -> []\n12 -> []\n18 -> [11, 12]\n9 -> []\n10 -> [18]\n13 -> []\n"
     ]
    }
   ],
   "source": [
    "MAX_NEIGHBORS = 8\n",
    "\n",
    "padding = torch.zeros(hidden_size)\n",
    "\n",
    "for iter in range(len(traversal_order)):\n",
    "    edge_tuple_list = traversal_order[iter]\n",
    "    \n",
    "    # all hidden vectors, of child nodes, for this iteration \n",
    "    child_hidden_vecs_iter = []\n",
    "    \n",
    "    edges_gates_iter = []\n",
    "    \n",
    "    parent_node_idx = []\n",
    "    \n",
    "    for node_x, node_y in edge_tuple_list:\n",
    "        \n",
    "        children = [node_z.idx for node_z in node_x.neighbors if node_z.idx != node_y.idx]\n",
    "        \n",
    "        print(str(node_x.global_idx) + \" -> \" + str(children))\n",
    "        \n",
    "        parent_node_idx.append(node_x.global_idx)\n",
    "\n",
    "        child_hidden_vecs = []\n",
    "\n",
    "        if len(children) > 0:\n",
    "            child_hidden_vecs = list(torch.index_select(initial_values, 0, torch.LongTensor(children)))\n",
    " \n",
    "        pad_len = MAX_NEIGHBORS - len(child_hidden_vecs)\n",
    "        child_hidden_vecs.extend([padding] * pad_len)\n",
    "        \n",
    "        child_hidden_vecs_iter.extend(child_hidden_vecs)\n",
    "        edges_gates_iter.extend(child_hidden_vecs)\n",
    "    \n",
    "    x = torch.stack(child_hidden_vecs_iter, dim=0)\n",
    "    child_hidden_vecs_iter = torch.mm(x, V)\n",
    "    child_hidden_vecs_iter = child_hidden_vecs_iter.view(-1, MAX_NEIGHBORS, hidden_size)\n",
    "    \n",
    "    y = torch.stack(edges_gates_iter, dim=0)\n",
    "    edges_gates_iter = torch.mm(y, B)\n",
    "    edges_gates_iter = edges_gates_iter.view(-1, MAX_NEIGHBORS, hidden_size)\n",
    "    \n",
    "    parent_node_hidden_vecs = torch.index_select(initial_values, 0, torch.tensor(parent_node_idx))\n",
    "    \n",
    "    if len(edge_tuple_list) > 2:\n",
    "        break\n",
    "    \n",
    "    \n",
    "    # \n",
    "    # child_hidden_vecs_iter_sum = torch.sum(child_hidden_vecs_iter, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [-0.7539, -0.9501, -1.1129],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000]],\n\n        [[-1.5638, -3.8015, -1.4700],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000]],\n\n        [[ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "child_hidden_vecs_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [-0.7539, -0.9501, -1.1129],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [-0.7539, -0.9501, -1.1129],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000]],\n\n        [[ 0.6203,  1.6438, -0.8755],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000]],\n\n        [[ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_gates_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2784,  0.6788,  0.2787],\n        [-0.1116, -0.5129, -0.5221],\n        [-0.2784,  0.6788,  0.2787]], grad_fn=<IndexSelectBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_node_hidden_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.mm(parent_node_hidden_vecs, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4184, -0.0385,  0.1612],\n        [-0.4550,  0.2893, -0.4657],\n        [ 0.4184, -0.0385,  0.1612]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_gates_iter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = q.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 3])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = edges_gates_iter + e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = nn.Sigmoid()(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6031, 0.4904, 0.5402],\n         [0.6031, 0.4904, 0.5402],\n         [0.6031, 0.4904, 0.5402],\n         [0.6031, 0.4904, 0.5402],\n         [0.6031, 0.4904, 0.5402],\n         [0.6031, 0.4904, 0.5402],\n         [0.6031, 0.4904, 0.5402],\n         [0.6031, 0.4904, 0.5402]],\n\n        [[0.5412, 0.8736, 0.2073],\n         [0.3882, 0.5718, 0.3856],\n         [0.3882, 0.5718, 0.3856],\n         [0.3882, 0.5718, 0.3856],\n         [0.3882, 0.5718, 0.3856],\n         [0.3882, 0.5718, 0.3856],\n         [0.3882, 0.5718, 0.3856],\n         [0.3882, 0.5718, 0.3856]],\n\n        [[0.6031, 0.4904, 0.5402],\n         [0.6031, 0.4904, 0.5402],\n         [0.6031, 0.4904, 0.5402],\n         [0.6031, 0.4904, 0.5402],\n         [0.6031, 0.4904, 0.5402],\n         [0.6031, 0.4904, 0.5402],\n         [0.6031, 0.4904, 0.5402],\n         [0.6031, 0.4904, 0.5402]]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4184, -0.0385,  0.1612],\n         [ 0.4184, -0.0385,  0.1612],\n         [ 0.4184, -0.0385,  0.1612],\n         [ 0.4184, -0.0385,  0.1612],\n         [ 0.4184, -0.0385,  0.1612],\n         [ 0.4184, -0.0385,  0.1612],\n         [ 0.4184, -0.0385,  0.1612],\n         [ 0.4184, -0.0385,  0.1612]],\n\n        [[ 0.1652,  1.9331, -1.3412],\n         [-0.4550,  0.2893, -0.4657],\n         [-0.4550,  0.2893, -0.4657],\n         [-0.4550,  0.2893, -0.4657],\n         [-0.4550,  0.2893, -0.4657],\n         [-0.4550,  0.2893, -0.4657],\n         [-0.4550,  0.2893, -0.4657],\n         [-0.4550,  0.2893, -0.4657]],\n\n        [[ 0.4184, -0.0385,  0.1612],\n         [ 0.4184, -0.0385,  0.1612],\n         [ 0.4184, -0.0385,  0.1612],\n         [ 0.4184, -0.0385,  0.1612],\n         [ 0.4184, -0.0385,  0.1612],\n         [ 0.4184, -0.0385,  0.1612],\n         [ 0.4184, -0.0385,  0.1612],\n         [ 0.4184, -0.0385,  0.1612]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
